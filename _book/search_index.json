[
["index.html", "Light-level geolocation analysis Preface", " Light-level geolocation analysis Simeon Lisovski, Martins Briedis, Kiran Danjahl-Adams, Lykke Pedersen, Sarah Davidson, …, Michael T. Hallworth, Michael Sumner, Simon Wotherspoon, Eli Bridge (201X) The Nuts and Bolts of Light-Level Geolocation Analyses. Journal X:xxx-xxx. DOI:00000.00 Preface Geolocation by light is a method of animal tracking that uses small, light-detecting data loggers (i.e. geolocators) to determine the locations of animals based on the light environment they move through. Technological and fieldwork issues aside, effective use of light level geolocation requires translation of a time series of light levels into geographical locations. Geographical locations derived from light-level data are subject to error that derives directly from noise in the light-level data, i.e. unpredictable shading of the light sensor due to weather or the habitat (Lisovski et al. 2012). Although light-level geolocation has provided a wealth of new insights into the annual movements of hundreds of bird species, researchers invariably struggle with the analytical steps needed to obtain location estimates, interpret them, present their results, and document what they have done. This manual has been written by some of the leading experts in geolocator analysis and is based on material created to run multiple international workshops. Thus, it pools code and experience gathered over the last decade. We hope that this collection of analysis using different open source software tools (R packages) helps both, newcomers and experienced users of light-level geolocation. References "],
["sturcture-of-the-manual.html", "Sturcture of the manual", " Sturcture of the manual This manual should allow users with very limited knowledge in R coding to perform a state-of-the-art analysis of geolocator data. Thus, we start with the very basics of loading packges 1 and data 3 and go into more detail along the way. Starting with twiligth annotation 4 we go into the different packages, illustrate the general workflow using example data and discuss potential pitfalls and provide some recommendations. While there are more R packages available (see: Merkel et al. 2016), we focus on the most freuqently used tools such as GeoLight 5, probGLS 6, SGAT 7 and FLightR 8. Furthermore, we provide code and ideas on simple representation of the results 9 and discuss Movebank as a data repository for geolocator tracks 10, References "],
["acknowledgements.html", "Acknowledgements", " Acknowledgements We want ot acknowledge … please add. Swiss National Science Foundation &amp; Swiss Ornithological Insitute: Workshop at Rigi NCEAS: Workshop Santa Barbara Migrate Technology: Support for workshops "],
["start.html", "Chapter 1 Getting started", " Chapter 1 Getting started To analyse light-level geolocator data in R we need a couple of R packages as well as functions that allow to run our code. We created a package called GeoLocTools that contains functions that are not nessesarily associated to a certain package put are used in this manual. Importantly the package can also runs a check on you system (function: setupGeolocation()), detecting packages that are already on your computer and installs the missing tools directly from CRAN or GitHub. The package requires devtools (install if nessesary using the install.packages() function). With devtools on your system, you are able to download and built as well as install R packages directly from GitHub (e.g. GeoLocTools). library(devtools) install_github(&quot;SLisovski/GeoLocTools&quot;) You are know able to load the package and run the setupGeolocation() function. We recommend to include this line at the beginning of each script you create for a geolocator analysis. Also check (every know and then), if there is a new version of GeoLicTools available. And if that is the case re-install the package using the same code you used for initial installation. library(GeoLocTools) setupGeolocation() The function returns “You are all set!” if it ran succesfully. Amongst other dependencies, the following geolocator specific packages are loaded by this function: twGeos GeoLight probGLS SGAT FLightR "],
["which-package-should-i-choose.html", "Which package should I choose", " Which package should I choose A geolocator analysis usually consists of three major steps. The first one, after downloading the data, is the annotation of twilight times, e.g. defining sunrise and sunset events using a light intensity threshold (go to Twilight Annotation). Next, most users are interested in a first look at the results using a simple threshold method (e.g. in GeoLight or SGAT). Depending on the question in min and the quality of the data, one can try to refine the location estimates using additional prior informaiton (such as speed distributions and spatial masks). This can be done using propGLS, SGAT and FLightR. GeoLight uses the threshold model to determine locations. Unlike the other packages described below, GeoLight doesn’t include a movement model and relies solely on the light-level data (Lisovski et al. 2012). However, the package provides tools for simple movement analysis, alternative location estimations (e.g. maximum likelihood approaches), and plotting utilities. GeoLight has been under constant development and new functionalities are added frequently, e.g. siteEstimate (Hiemer et al. 2018). Go to GeoLight probGLS …. Go to probGLS SGAT pronounced “tags backwards” can be run using a curve method (e.g. using the slope if the increasing and decresing light during twilight periods) but also uses the threshold method (e.g. using single twilight events). The method uses an MCMC simulation to refine location estimates and positions are estimated based on 1) the observed difference between known twilights and twilights recorded by the unit, 2) a movement model and 3) a spatial mask. The positions are estimated within a Bayesian framework and it is relatively easy to implement own ideas (e.g. special masks or bimodal movement behavior). In this manual, we also describe the so called group Modelthat has been proven to be a good model for many migratory songbirds since it increases accuracy and precision of stationary sites (Dhanjal-Adams et al. 2018). Of all the described packages, SGAT is the most coding intensive method. Go to SGAT FLightR uses a movement model, the relationship between observed and expected light-levels and implements a particle filter to estimate locations. Of the three packages FLightR is the most computationally intense method and running the final model takes hours to complete. Yet if the data quality is good it has proven to be the be very accurate (Rakhimberdiev et al. 2016). FLightR works best with data recorded from tags that record a wide spectrum of light intensities with high frequency (2-5 min), resulting in multible recordings of light during the twilight periods. More information about the underlying model can be found in (Rakhimberdiev et al. 2015). Go to FLightR "],
["datasets.html", "Chapter 2 The Datasets", " Chapter 2 The Datasets To illustrate the capabilities of the different packages, discuss the potential pitfalls and provide some recommendations, we will use raw geolocator data from three individuals of different species. The data is publised on Movebank @ref{movebank} and can be downloaded directly using the R package move (to be done and to be tested!). TagID Species Tag type Movebank information M034 Red-backed Shrike Integio (Movement Technology Ltd.) TBA xxx European bee-eater PAM (Swiss Ornithological Institute) TAB xxx xx Bunting Eli TAB Differences Recording/measurement frequency Sensitivity "],
["loadingData.html", "Chapter 3 Loading data into R", " Chapter 3 Loading data into R The first step is to load your raw data into R. Different geolocator types (e.g. from different manufacturers or different series) provide raw data in different formats. And while there are functions available to read a whole range of formats, you may have to eiter write your own function, use simple read text utilites or get in touch with the package managers to write code that fits your format if it is not yet implemented. The most frequently used geolocators provide files with the extention, .lux (Migrate Technology Ltd), .lig (BAS, Biotrack) or .glf (Swiss Ornithological Insitute). The functions readMTlux, ligTrans and glfTrans allows you to read these files. The documentations of the different packages may help to provide information on how to read other fiels (e.g. ?GeoLight). A short note on naming and saving of data files (final results and intermediate steps): Notably, if you want to analyse a whole range of geolocator tracks (from different species or sites) and with different methods, we recommend to use a consistent naming convention. This helps to not loose the overview, but most importantly it allows to run the same code for saving and reading of data once you defined a set of metadata information. And while you may want to adjust to personal preference we also recommend to have a fixed and consistent folder structure for your analysis. E.g.: RawData RCode Results In case of multi-species analysis we recommend to have species folders within those folders. We can then define metadata information on the individual, the species, as the deployment location. ID &lt;- &quot;14SA&quot; Species &lt;- &quot;MerApi&quot; wd &lt;- &quot;Data&quot; # Subfolder of Analysis lon.calib &lt;- 11.96 lat.calib &lt;- 51.32 By using the above metadata we can use the paste0 command to include this information in reading and writing of files. raw &lt;- glfTrans(paste0(wd, &quot;/RawData/&quot;, Species, &quot;/&quot;, ID, &quot;.glf&quot;)) names(raw) &lt;- c(&quot;Date&quot;, &quot;Light&quot;) raw$Light &lt;- log(raw$Light+0.0001) + abs(min(log(raw$Light+0.0001))) head(raw) ## Date Light ## 1 2015-07-10 00:00:00 0 ## 2 2015-07-10 00:05:00 0 ## 3 2015-07-10 00:10:00 0 ## 4 2015-07-10 00:15:00 0 ## 5 2015-07-10 00:20:00 0 ## 6 2015-07-10 00:25:00 0 Adding to the confucion of different raw data types, the read functions also provide different output. However, the most important columns are, Date Light and these columns need to be in a specific format with Date beeing a POSIX. class and light beeing numeric intergers. Check with the following line of code: str(raw) ## &#39;data.frame&#39;: 112161 obs. of 2 variables: ## $ Date : POSIXct, format: &quot;2015-07-10 00:00:00&quot; &quot;2015-07-10 00:05:00&quot; ... ## $ Light: num 0 0 0 0 0 0 0 0 0 0 ... Do I need to log-transform my raw light measurements? @ Eldar - please add! "],
["twilight.html", "Chapter 4 Twilight Annotation", " Chapter 4 Twilight Annotation There are a few options for how to define / edit twilights. All tools discussed in this manual require as one of their inputs a dataframe containing the times of sunrise and sunset (henceforth twilights) for the duration of the study period. The twilight times are estimated based on a light-level threshold, which is the light value that seperates day from night - values above the threshold indicate the sun has risen and values below the threshold value indicate the sun has set. There are a few options for how to generate the twilight data. twilightCalc is one function that allows transitions to be defined and is part of the GeoLight package. Given the much better realisation of this process in TwGeos, we will not discuss the GeoLight version of defining twilights. twGeos provides an easier to use and more interactive process that is called preprocessLight. An important input, besides the raw data, is a pre-defined light intensity threshold value. How do I know which thresold to use? You should choose the lowest value that is consistently above any noise in the nighttime light levels. For many .lig data sets 2.5 is above any nighttime noise. For forest interior, ground dwelling species a lower threshold may be helpful - especially if there isn’t much ‘noise’ during the night. A threshold of 1 may be appropriate for such species. It is a good idea to plot (parts) of the dataset and see how the threshold fits into the light recordings: threshold &lt;- 2.5 par(mfrow = c(1, 1), mar = c(2, 2, 2, 2) ) with(raw[2000:5000,], plot(Date, Light, type = &quot;o&quot;, pch = 16, cex = 0.5)) abline(h=threshold, col=&quot;orange&quot;, lty = 2, lwd = 2) Another useful plot can be created using lightImage; In the resulting figure, each day is represented by a thin horizontal line that plots the light values as grayscale pixels (dark = low light and white = maximum light) in order from bottom to top. a light image allows you to visualize an entire data set at once, and easily spot discrepancies in light to dark transitions. Additionally, you can add the sunrise and sunset times of the deployment or retrieval locaitons (using addTwilightLine). This may help to spot inconsistncies in the dataset, e.g.: * time shifts - resulting in a good overlap of twilight times at the beginning but a systematic shift between expected and recorded twilight times. * false time zone - if the predicted sunrise and sunset times are shifted up- or downwards it is highly likely that your raw data is not recorded (or has been transformed) in GMT (or UTC). Check with producer or data provider. Furthermore, the lines can help to identify the approximate timing of departure and arrival to the known deployment or retrieval site and this may help to identify calibration periods that are requirred in the next steps of the analysis. offset &lt;- 12 # adjusts the y-axis to put night (dark shades) in the middle lightImage( tagdata = raw, # light data offset = offset, zlim = c(0, 20)) # y axis # addTwilightLine(lon = lon.calib, lat = lat.calib, zenith = 96) In the next step, we want to define daily sunrise and sunset times. preprocessLight is an interactive function for editing light data and deriving these twilight times Note: if you are working on a Mac you must install Quartz first (https://www.xquartz.org) and then set gr.Device to “x11” in the function. If you are working with a virtual machine, the function may not work at all. Detailed instructions of how to complete the interactive process can be found by running the following code: ?preprocessLight Below, we explain the major functionalities. When you run, twl &lt;- preprocessLight(raw, threshold = threshold, offset = offset, lmax = 20, # max. light value (adjust if contrast between night and day is weak) gr.Device = &quot;x11&quot;) # x11 works on a mac (if Quarz has been installed and works on most Windows machines too) two windows will appear. Move them so they are not on top of each other and you can see both. They should look like a big black blob (Kiran`s expression). This identifies the “nightime” period over time. The top of the blob shows all the sunrises and the bottom of blob shows all the sunsets. You can note for instance that the days get longer at the beggining of the time series, because the blob gets wider. Step 1. Click on the window entitled “select subset” with the left mouse button to choose start and right mouse button to choose end. You will notice that the red bar at the top moves and that the second window zooms into that time period. Select when you want your time series to start and end. This allows you to ignore for instance periods of nesting. Once you are happy with the start and end of the timeseries press “a” on the keyboard to accept and move to next step. Step 2. click on the window entitled “Find twilights” and the second window will zoom in. All you need to do here is click in the dark part of the image and this will identify all the sunrises (orange) and sunsets (blue) based on the threshold defined in the presvious section. Press “a” on the keyboard to accept and move to next step. Step 3. This step is for adding or deleting points.You can often skip it by pressing “a” on the keyboard. However, if you do want to add a point, you can click on the “Insert twilights” window to zoom in and then left click on the other window with the left mouse button to add a sunrise, and the right button to add a sunset some. You can use “u” on the keyboard to undo any changes, and “d” to delete any points which are extra. Press “a” to move to next step. Step 4. This allows you to find points which have been miss-classified (often because the bird was in the shade or in a burrow) and to move the respective sunrise. Choose a point by clicking on it in the “edit twilights” window and the other window will displaz the sunrise (or sunsets) from the presvious and next days (purple and green) relative to the current sunrise or sunset. Thus if it is very much out, you can estimate the sunset on that day would likely have been sometime between that of the day before and after. You can then left click at the point where you want the day to start and press “a” to accept and move the sunrise or sunset. You will notice the red line then moves. Do this for as many points as necessary. Then close the windows with “q”. IMPORTANT Save the output file so that you never have to do this step again. Best to save as a .csv file that can then easily be read into R at a later time. The output contains the following importnatn information: Twilight The date and time of the sunrise/sunset events Rise whether the Twilight is a sunrise (TRUE) or a sunset (FALSE) Deleted whether you marked this twilight with a “d”, that means it is still in the file and can/should be exlcuded later on. Marker (see detailed description in ?preprocessLight) Inserted (whether this Twilight was manually inserted) Twilight3 (the original Twilight. Only different to Twilight if you edited the timing) Other processes like twilightCalc or the software TAGSproduce different outputs but it is preferred to get them into this format (at least with the columns Twilightand Rise), since you can go ahead with any analysis you want using these two columns (note: do not save these two columns only, since the other inforamtion is important to reproduce your analysis). To save this file we use the metadata variables that were defined above: write.csv(twl, paste0(wd, &quot;/Results/&quot;, Species, &quot;/&quot;, ID, &quot;_twl.csv&quot;), row.names = F) This can later be loaded using the following code (note, that you have to define the class type POSIXC for the date): twl &lt;- read.csv(paste0(wd, &quot;/Results/&quot;, Species, &quot;/&quot;, ID, &quot;_twl.csv&quot;)) twl$Twilight &lt;- as.POSIXct(twl$Twilight, tz = &quot;GMT&quot;) # get the Twilight times back into the POSIX. class format The result of this first part that is independent of which package/analysis will be used next is the twiligth file that shoudl at least look like (can have more columns): head(twl[,c(1,2)]) ## Twilight Rise ## 1 2015-07-15 19:34:02 FALSE ## 2 2015-07-16 03:01:00 TRUE ## 3 2015-07-16 19:43:53 FALSE ## 4 2015-07-17 02:51:06 TRUE ## 5 2015-07-17 19:48:53 FALSE ## 6 2015-07-18 02:46:06 TRUE "],
["cleaningfiltering-twilight-times.html", "Cleaning/Filtering twilight times", " Cleaning/Filtering twilight times Automated filtering of twilight times should be handeled carefully. There is no perfect function that cleans your twilight file. However, twilightEdit can help to filter and remove (mark them as deleted) outliers (e.g. false twiligths). The filtering and removing of twilight times is based on a set of rules: if a twilight time is e.g. 45 minutes (outlier.mins) different to its surrounding twilight times, and these sourrounding twilight times are within a certain range of minutes (stationary.mins), then the twiligth times will be adjusted to the median of the sourrounding twilights. if a twilight time is e.g. 45 minutes (outlier.mins) different to its surrounding twilight times, but the sourrounding twilight times are more variable then you would expect them to bee if they were recorded during stationary behavior, then the twiligth time will be marked as deleted. The argument windows defines the number of twilight times sourrounding the twilight in focus (e.g. same as in conventional moving window methods). twl &lt;- twilightEdit(twilights = twl, offset = offset, window = 4, # two days before and two days after outlier.mins = 45, # difference in mins stationary.mins = 25, # are the other surrounding twilights within 25 mins of one another plot = TRUE) In this particualar case and with the paramters, four twilight times have been corrected. Based on the output, you can also exlude them for further analysis. While you can also save the output file, we recomment to archive the twiligth file from above and redo the twilightEditafter reading in the archived twiligth file from above. Important: This method helps to adjust and remove twilight times that are either outliers, false twiligths given a set of rules. While subjective to a certain degree as well as repdroducabel, the method may not be able to detect all false twiligth times and may even remove correct entries during fast migration periods. "],
["GeoLight.html", "Chapter 5 GeoLight", " Chapter 5 GeoLight "],
["probGLS.html", "Chapter 6 probGLS", " Chapter 6 probGLS "],
["SGAT.html", "Chapter 7 SGAT", " Chapter 7 SGAT General introduction… To illustrate the SGAT analysis, we use the European bee-eater dataset. The light intensities were recorded by a geolocator from the Swiss Ornithological Insitute, measuring light every xx minutes writing the mean of every xx measurements. We first define the metadata and read in the raw recordings. We skip the twilight definition process but read in the twiligth file that has been generated using preprocessLight. Note: it is required to retransform the Twilight column into the POSIXcformat. ID &lt;- &quot;14SA&quot; wd &lt;- &quot;Data&quot; Species &lt;- &quot;MerApi&quot; lon.calib &lt;- 11.96 lat.calib &lt;- 51.32 raw &lt;- glfTrans(paste0(wd, &quot;/RawData/&quot;, Species, &quot;/&quot;, ID, &quot;.glf&quot;)) names(raw) &lt;- c(&quot;Date&quot;, &quot;Light&quot;) raw$Light &lt;- log(raw$Light+0.0001) + abs(min(log(raw$Light+0.0001))) twl &lt;- read.csv(paste0(wd, &quot;/Results/&quot;, Species, &quot;/&quot;, ID, &quot;_twl.csv&quot;)) twl$Twilight &lt;- as.POSIXct(twl$Twilight, tz = &quot;GMT&quot;) twl &lt;- twl[!twl$Deleted,] raw &lt;- subset(raw, Date&gt;=min(twl$Twilight) &amp; Date&lt;=max(twl$Twilight)) # clipping raw data to relevant extent We can have a look into the data using the lightImage function from the TwGeos package: offset &lt;- 12 # adjusts the y-axis to put night (dark shades) in the middle lightImage( tagdata = raw, offset = offset, zlim = c(0, 20)) tsimagePoints(twl$Twilight, offset = offset, pch = 16, cex = 1.2, col = ifelse(twl$Rise, &quot;firebrick&quot;, &quot;cornflowerblue&quot;)) "],
["calibration-sgat.html", "7.1 Calibration (SGAT)", " 7.1 Calibration (SGAT) See general introduction and discusssion on calibration: @ref{calibration}. Calibration for the SGAT process is similar to the calibration perfomed in the GeoLight analysis. Both, the zero and the median sun elevation angles, as well as the parameters for the error distribution of the twiligth times is crucial for the analysis. However, while we use sun elevation angles in GeoLight we need the zenith angle in SGAT. The difference is trivial; sun elevation angle refers to the deviation of the sun relative to the horizon, whereas the zenith angle refers to the deviation from the zenith. Thus, civil twilight is defined as the time when the sun elevation angle is -6 degrees which equals a zenith angle of 96 degrees. The simple conversion of sun elevation angle to zenith angle is: \\[zenith = 90 - sun elevation angle\\] There are multible ways to define the time period for calibration. Best is certainly if you know when the individual left the deployment site and if there where a couple of weeks between deployment and departure. In many instances the departure date (or the arrival to the retrieval site) is unknown. The lightImage together with the tsimageDeploymentLinecan help to define suitable period (the right time period can be optimized by changing the date in the tm.calib vector and plotting the lines over and over again until you are sure that you have selected the beginning and the end of the calibration period). Again, the longer the period the better, but periods that are influenced by e.g. breeding in nest boxes or by movements should be excluded. lightImage( tagdata = raw, offset = offset, zlim = c(0, 20)) tsimageDeploymentLines(twl$Twilight, lon.calib, lat.calib, offset, lwd = 2, col = &quot;orange&quot;) tm.calib &lt;- as.POSIXct(c(&quot;2015-07-20&quot;, &quot;2015-08-29&quot;), tz = &quot;GMT&quot;) abline(v = tm.calib, lwd = 2, lty = 2, col = &quot;orange&quot;) d_calib &lt;- subset(twl, Twilight&gt;=tm.calib[1] &amp; Twilight&lt;=tm.calib[2]) Using the calibation subset of the twl table we can perform the calibration: calib &lt;- thresholdCalibration(d_calib$Twilight, d_calib$Rise, lon.calib, lat.calib, method = &quot;gamma&quot;) This is how a calibration time series should look like. Based in theory it should follow a gamma or a log-normal distribution (both can be used in SGAT). What we can see, is that the recorded twilight times most frequently deviation approx. 12 minutes. However, deviations of up to 50 minutes have been recorded. For the following analysis, we need the zenith angle for both the zero deviation (0, and second number in return vector e.g. calib[2]) and the most frequent median deviation (1, and the first number in the return vector e.g. calib[1]). Additionally we need the parameters of the error distribution (alpha parameters, e.g. calib[3:4]). zenith &lt;- calib[1] zenith0 &lt;- calib[2] alpha &lt;- calib[3:4] "],
["alternative-hill-ekstrom-calibration.html", "7.2 Alternative - Hill-Ekstrom Calibration", " 7.2 Alternative - Hill-Ekstrom Calibration For the bee eaters and many other species the breeding season that is often also were the loggers are delpoyed is a very speciel period during which the birds use different habitats and show different behaviors. This is of course suboptimal for calibration since it would lead to good estimates for the breeding grounds when we knwo the exact location and biased estimates for the rest of the year. We can therefore try and estimate an alternative zenith angle based in the Hill-Ekstrom theory that the rigth zenith anlge should lead to the lowest variance in latitude estimates during stationary periods. And the latter is most pronounced around the equinox. The following bits of code draws a basic path and then compares different zeniths to find the one with the lowest variation. It then uses that new zenith with the least sd in the threshold model. In the findHEZenithfunction, the tol argument defines how many locations shoudl be linearly interpolated around the equinox. Large values lead to larger periods with interpolated values. For this type of calibration it makes sense to play with this value but in general it is recommended to set it to a low value (e.g. 0.08). If the tracked individual has been stationary during the time of the equinox this period provides the best data for the Hill-Ekstrom calibration. (zenith_sd &lt;- findHEZenith(twl, tol=0.01, range=c(300,550))) ## [1] 93.5 The top panel shows the entire path (latitude) using different zenith angles with the black line indicating the latiude estimates with the smalles variation within the specified range (in between the two blue dashed lines). One need to be quite sure that the individual did not move during this period. The lower panes shows the actual variation for each across a range of zenith angles. It is good if one can see a clear minimum in this curve. In this case, there is no real diffrence between the two calibrations. If a difference will be detected (&gt;0.5 degrees), one should consider to adjust the zenith angles calculated from the breeding site. zenith &lt;- zenith + abs(zenith0-zenith_sd) zenith0 &lt;- zenith_sd "],
["FLightR.html", "Chapter 8 FLightR", " Chapter 8 FLightR "],
["presentation.html", "Chapter 9 Presentation of results", " Chapter 9 Presentation of results "],
["movebank.html", "Chapter 10 Movebank", " Chapter 10 Movebank "],
["references.html", "References", " References "]
]
